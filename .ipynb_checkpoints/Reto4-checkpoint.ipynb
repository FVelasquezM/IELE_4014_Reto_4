{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IELE_4014**  \n",
    "**Felipe Velásquez Montoya**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; *cód estudiante:* 201632422\n",
    "# Reto 3\n",
    "Problema de regresión lineal para predecir la calidad del vino (https://archive.ics.uci.edu/ml/datasets/Wine+Quality) utilizando desarrollo propio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 0**   Instalanción de librería numpy para facilitar operaciones con matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de dependencias random, math y numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa numpy para facilitar las operaciones con matrices\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo de la regresión lineal\n",
    "\n",
    "Se muestra, a continuación, el código de la regresión lineal y sus respectivas funciones auxiliares. se inicia con la función *train_test_split*, diseñada para imitar el comportamiento de su homónima en sklearn. \n",
    "\n",
    "Este método divide un conjunto de datos en datos de entrenamiento y datos de prueba. Lo anterior se hace de manera aleatoria, por lo que no hay garantía alguna de que los conjuntos resultantes tengan la misma distribución de probabilidad.\n",
    "\n",
    "La metodología utilizada consiste en recorrer las listas y generar un número al azar por cada elemento, si el número generado es menor o igual a la rata dada por el tamaño del conjunto de entrenamiento dividido entre el tamaño total del conjunto, se añade al conjunto de entrenamiento. De modo contrario, se añade al conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método auxiliar que divide los datos entre entranamiento y test\n",
    "#test_ratio es el porcentaje total de los datos que se usará para test.\n",
    "#Hace la división al azar utilizando random.random\n",
    "#Pre: X_set  y y_set deben tener el mismo orden, es decir, para todo elemento X_i \n",
    "# de la X_set, y_i en el conjunto y_set debe ser su respectiva pareja.\n",
    "def train_test_split(X_set, y_set, test_ratio):\n",
    "    \n",
    "    test_size = math.floor(test_ratio*len(X_set))\n",
    "    current_test_size = 0\n",
    "        \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        \n",
    "        if random.random() <= test_ratio and current_test_size < test_size:\n",
    "            X_test.append(X_set[i])\n",
    "            y_test.append(y_set[i])\n",
    "            current_test_size += 1\n",
    "        else:\n",
    "            X_train.append(X_set[i])\n",
    "            y_train.append(y_set[i])\n",
    "    \n",
    "    #En caso de que test no quede del tamaño requerido, se sacan los últimos elementos de train\n",
    "    while len(X_test) != test_size:\n",
    "        X_test.append(X_train.pop())\n",
    "        y_test.append(y_train.pop())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta, a continuación, la clase LinearRegression. Esta contiene la función *fit* que utiliza un descenso de gradiente estocástico para entrenar el modelo. La función *residual_sum_of_squares* sirve de función auxiliar y la función *rsquared* sirve para la evaluación.\n",
    "\n",
    "*rsquared* calcula el r cuadrado de la regresión.   \n",
    "*residual_sum_of_squares* calcula la suma de cuadrados de los residuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, suppress_output = False):\n",
    "        self.W = None\n",
    "        self.suppress_output = suppress_output\n",
    "\n",
    "    #Descenso estocástico de gradiente para regresión lineal.\n",
    "    #training_data_X es una matriz que representa el conjunto de x_i's\n",
    "    #training_data_y es una matriz que representa el conjunto de y_i's. Esta matriz tiene únicamente una \n",
    "    #Pre: training_data_X  y training_data_y deben tener el mismo orden, es decir, para todo elemento X_i \n",
    "    # de la matriz training_data_X, y_i en la matriz training_data_y debe ser su respectiva pareja.\n",
    "    # ejemplo, la fila 0 de training_data_X tiene como respectivo valor y el que está dado por \n",
    "    # la fila 0 de training_data_y\n",
    "    def fit(self, training_data_X, training_data_y,learning_rate= 0.0001, max_iterations = 10000):\n",
    "    \n",
    "        #Para evitar que la embarre y ponga un learning rate demasiado alto que lleve a que el método no converja \n",
    "        if(learning_rate > 0.0001):\n",
    "            learning_rate = 0.0001\n",
    "    \n",
    "        #Se inicializa W en ceros, de dimensión (columnas X, 1).\n",
    "        #Se hace así para que no se tenga que transponer W.\n",
    "        W = np.zeros(shape = (1, len(training_data_X[0])))\n",
    "    \n",
    "        iterations = 0\n",
    "        no_improv_it = 0\n",
    "        last_error = 0\n",
    "        new_error = 0\n",
    "    \n",
    "        #Se estimará el gradiente a partir, únicamente, de uno de los datos\n",
    "        while iterations < max_iterations and no_improv_it < 100 :\n",
    "        \n",
    "            #Seleccionar un dato al azar.\n",
    "            i = math.floor(random.random()*len(training_data_X))\n",
    "    \n",
    "            #Calcular error del dato seleccionado al azar.\n",
    "            e = np.dot(training_data_X[i], W.transpose())[0] - training_data_y[i]\n",
    "            #Estimar gradiente con el error anterior\n",
    "            estimated_grad = np.multiply(e, training_data_X[i])\n",
    "        \n",
    "            W = W - np.multiply(learning_rate, estimated_grad)\n",
    "            \n",
    "            if last_error <= e:\n",
    "                no_improv_it += 1\n",
    "            elif last_error > e:\n",
    "                no_improv_it = 0\n",
    "        \n",
    "            last_error = e\n",
    "            iterations += 1        \n",
    "        \n",
    "        self.W = W\n",
    "        \n",
    "        if not self.suppress_output:\n",
    "            print(\"----------------------------------------------\")\n",
    "            print(\"W found: %s\" % W)\n",
    "            print(\"R^2 found for the model: %s\" % self.rsquare(training_data_X, training_data_y))\n",
    "           \n",
    "    def rsquare(self, test_data_X, test_data_y):\n",
    "    \n",
    "        residual_sum = self.residual_sum_of_squares(test_data_X, test_data_y)\n",
    "    \n",
    "        mean = np.mean(test_data_y)\n",
    "        \n",
    "        total_sum_squares = 0\n",
    "        for i in range(0, len(test_data_y)):\n",
    "            total_sum_squares +=  math.pow(test_data_y[i] - mean,2)\n",
    "    \n",
    "        return 1 - residual_sum/total_sum_squares\n",
    "     \n",
    "    #Calcula el error de la función, se usa sólo una vez por iteración.\n",
    "    def residual_sum_of_squares(self, training_data_X, training_data_y):\n",
    "    \n",
    "        sum = 0\n",
    "        for i in range(0, len(training_data_X)):\n",
    "            sum+= math.pow(training_data_y[i] - np.dot(training_data_X[i] , self.W.transpose())[0],2)\n",
    "    \n",
    "        return 0.5 * sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución del problema de regresión lineal\n",
    "Ya expuesta la regresión lineal que se desarrolló, se probará la misma atacando el problema de estimación de calidad del vino blanco.   \n",
    "Se inicia cargando los datos del CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas de la matriz: 4898\n",
      "Columnas de la matriz: 12\n"
     ]
    }
   ],
   "source": [
    "data_matrix = np.loadtxt(open(\"./WineQuality/winequality-white.csv\", \"rb\"), delimiter=\";\", skiprows=1)\n",
    "\n",
    "print(\"Filas de la matriz: \" + str(len(data_matrix)))\n",
    "print(\"Columnas de la matriz: \" + str(len(data_matrix[0])))\n",
    "\n",
    "X = np.resize(data_matrix, (len(data_matrix), len(data_matrix[0])-1))\n",
    "y = data_matrix[:,len(data_matrix[0])-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se utiliza el método train_test_split para obtener el los conjuntos de prueba y de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño X entrenamiento: 2898 | Tamaño y entrenamiento: 2898\n",
      "Tamaño X prueba: 2000 | Tamaño y prueba: 2000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_ratio = 2000.00/float(len(X))) \n",
    "\n",
    "print(\"Tamaño X entrenamiento: %s | Tamaño y entrenamiento: %s\" % (len(X_train), len(y_train)))\n",
    "print(\"Tamaño X prueba: %s | Tamaño y prueba: %s\" % (len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de entrenamiento se vuelve a partir, esta vez en conjuntos de 100, 1000 y 2898 datos. Como se constata por la salida de consola, ahora se tienen tres conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Set de entrenamiento 0\n",
      "    Tamaño X de entrenamiento: 100 | Tamaño y de entrenamiento: 100\n",
      "-----------------------------\n",
      "Set de entrenamiento 1\n",
      "    Tamaño X de entrenamiento: 1000 | Tamaño y de entrenamiento: 1000\n",
      "-----------------------------\n",
      "Set de entrenamiento 2\n",
      "    Tamaño X de entrenamiento: 2898 | Tamaño y de entrenamiento: 2898\n"
     ]
    }
   ],
   "source": [
    "sizes = [100.00, 1000.00, 2898.00]\n",
    "X_train_array = []\n",
    "y_train_array = []\n",
    "\n",
    "for i in sizes:\n",
    "    Xy = train_test_split(X_train, y_train, test_ratio = 1.00 - i/float(len(X_train)))\n",
    "    X_train_array.append(Xy[0])\n",
    "    y_train_array.append(Xy[2])\n",
    "    \n",
    "#Verificar tamaños de los nuevos sets de entrenamiento\n",
    "for i in range(0, len(X_train_array)):\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Set de entrenamiento %s\" % i)\n",
    "    print(\"    Tamaño X de entrenamiento: %s | Tamaño y de entrenamiento: %s\" \n",
    "          % (len(X_train_array[i]), len(y_train_array[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se entrenan tres regresiones lineales, una con cada conjunto de entrenamiento y se prueba su desempeño con el conjunto de datos de prueba. Como podrá observarse, el desempeño obtenido por el modelo es extremadamente pobre en todos los casos, sugiriendo que el problema no puede ser resuelto por medio de una regresión lineal. Debe resaltarse que dado que no se reservaron datos de validación, los modelos no son comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Modelo entrenado con 100.0 datos obtuvo un R cuadrado de -1.8782959123186918\n",
      "El Modelo entrenado con 1000.0 datos obtuvo un R cuadrado de -1.7596193294154268\n",
      "El Modelo entrenado con 2898.0 datos obtuvo un R cuadrado de -1.7425412061483234\n"
     ]
    }
   ],
   "source": [
    "linreg_array = []\n",
    "linreg_score = []\n",
    "\n",
    "for i in range(0, len(X_train_array)):\n",
    "    #Se entrena la regresión lineal con el conjunto de entrenamiento correspondiente.\n",
    "    lr = LinearRegression(suppress_output = True)\n",
    "    lr.fit(X_train_array[i], y_train_array[i], learning_rate = 0.000001)\n",
    "    linreg_array.append(lr)\n",
    "    \n",
    "    #Se prueba la regresión lineal con los conjuntos de prueba:\n",
    "    linreg_score.append(linreg_array[i].rsquare(X_test, y_test))\n",
    "    \n",
    "    #Se imprimen los resultados del modelo\n",
    "    print(\"El Modelo entrenado con %s datos obtuvo un R cuadrado de %s\" % (sizes[i], linreg_score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista del pobre desempeño obtenido se intentará entrenar la regresión con un conjunto de datos estandarizados.   \n",
    "Se importa sklearn para utilizar su función MinMaxScaler de estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede comprobarse a continuación, los resultados obtenidos estandarizando los datos fueron aún más pobres que con los datos crudos. De nuevo, sugiriendo que el problema no se puede resolver por medio de un modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas de la matriz: 4898\n",
      "Columnas de la matriz: 12\n",
      "Tamaño X entrenamiento: 2898 | Tamaño y entrenamiento: 2898\n",
      "Tamaño X prueba: 2000 | Tamaño y prueba: 2000\n",
      "-----------------------------\n",
      "Set de entrenamiento 0\n",
      "    Tamaño X de entrenamiento: 100 | Tamaño y de entrenamiento: 100\n",
      "-----------------------------\n",
      "Set de entrenamiento 1\n",
      "    Tamaño X de entrenamiento: 1000 | Tamaño y de entrenamiento: 1000\n",
      "-----------------------------\n",
      "Set de entrenamiento 2\n",
      "    Tamaño X de entrenamiento: 2898 | Tamaño y de entrenamiento: 2898\n",
      "El Modelo entrenado con 100.0 datos obtuvo un R cuadrado de -4.43474729859357\n",
      "El Modelo entrenado con 1000.0 datos obtuvo un R cuadrado de -4.436704686590301\n",
      "El Modelo entrenado con 2898.0 datos obtuvo un R cuadrado de -4.426233465500838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_matrix_norm = np.loadtxt(open(\"./WineQuality/winequality-white.csv\", \"rb\"), delimiter=\";\", skiprows=1)\n",
    "\n",
    "print(\"Filas de la matriz: \" + str(len(data_matrix_norm)))\n",
    "print(\"Columnas de la matriz: \" + str(len(data_matrix_norm[0])))\n",
    "\n",
    "X_norm = np.resize(data_matrix_norm, (len(data_matrix_norm), len(data_matrix_norm[0])-1))\n",
    "y_norm = data_matrix[:,len(data_matrix[0])-1]\n",
    "\n",
    "X_norm = MinMaxScaler().fit_transform(X_norm)\n",
    "\n",
    "y_norm= np.array([y_norm]).transpose()\n",
    "y_norm = MinMaxScaler().fit_transform(y_norm)\n",
    "\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y_norm, test_ratio = 2000.00/float(len(X))) \n",
    "\n",
    "print(\"Tamaño X entrenamiento: %s | Tamaño y entrenamiento: %s\" % (len(X_train_norm), len(y_train_norm)))\n",
    "print(\"Tamaño X prueba: %s | Tamaño y prueba: %s\" % (len(X_test_norm), len(y_test_norm)))\n",
    "\n",
    "sizes_norm = [100.00, 1000.00, 2898.00]\n",
    "X_train_array_norm = []\n",
    "y_train_array_norm = []\n",
    "\n",
    "for i in sizes_norm:\n",
    "    Xy_norm = train_test_split(X_train_norm, y_train_norm, test_ratio = 1.00 - i/float(len(X_train_norm)))\n",
    "    X_train_array_norm.append(Xy_norm[0])\n",
    "    y_train_array_norm.append(Xy_norm[2])\n",
    "    \n",
    "#Verificar tamaños de los nuevos sets de entrenamiento\n",
    "for i in range(0, len(X_train_array_norm)):\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Set de entrenamiento %s\" % i)\n",
    "    print(\"    Tamaño X de entrenamiento: %s | Tamaño y de entrenamiento: %s\" \n",
    "          % (len(X_train_array_norm[i]), len(y_train_array_norm[i])))\n",
    "    \n",
    "linreg_array_norm = []\n",
    "linreg_score_norm = []\n",
    "\n",
    "for i in range(0, len(X_train_array)):\n",
    "    #Se entrena la regresión logística con el conjunto de entrenamiento correspondiente.\n",
    "    lr = LinearRegression(suppress_output = True)\n",
    "    lr.fit(X_train_array_norm[i], y_train_array_norm[i])\n",
    "    linreg_array_norm.append(lr)\n",
    "    \n",
    "    #Se prueba la regresión logística con los conjuntos de prueba:\n",
    "    linreg_score_norm.append(linreg_array_norm[i].rsquare(X_test_norm, y_test_norm))\n",
    "    \n",
    "    #Se imprimen los resultados del modelo\n",
    "    print(\"El Modelo entrenado con %s datos obtuvo un R cuadrado de %s\" % (sizes_norm[i], linreg_score_norm[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar que la regresión lineal desarrollada sirve correctamente, se hará un modelo sobre un conjunto de datos sintético diseñado para regresiones lineales. Para realizar esto se utilizará la librería mglearn para generar el conjunto de datos, adicionalmente, se comparará el desempeño de la regresión lineal desarrollada con la de los modelos de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (0.1.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (3.1.1)\n",
      "Requirement already satisfied: imageio in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (0.21.3)\n",
      "Requirement already satisfied: cycler in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (0.10.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (1.17.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from mglearn) (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\f.velasquez\\appdata\\local\\conda\\conda\\envs\\jupyterlab-1.0.2_1\\lib\\site-packages (from matplotlib->mglearn) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mglearn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->mglearn) (2.4.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->mglearn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->mglearn) (0.13.2)\n",
      "Requirement already satisfied: six in c:\\users\\f.velasquez\\appdata\\local\\conda\\conda\\envs\\jupyterlab-1.0.2_1\\lib\\site-packages (from cycler->mglearn) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\f.velasquez\\appdata\\roaming\\python\\python37\\site-packages (from pandas->mglearn) (2019.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\f.velasquez\\appdata\\local\\conda\\conda\\envs\\jupyterlab-1.0.2_1\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->mglearn) (41.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R cuadrado para los datos sintéticos utilizando el modelo propio: 0.8085714114452791\n"
     ]
    }
   ],
   "source": [
    "import mglearn\n",
    "X_synth, y_synth = mglearn.datasets.make_wave(n_samples=5000)\n",
    "\n",
    "X_train_synth, X_test_synth, y_train_synth, y_test_synth = train_test_split(X_synth, y_synth, test_ratio = 0.3*5000/float(len(X))) \n",
    "\n",
    "lr_synthetic = LinearRegression(suppress_output = True)\n",
    "lr_synthetic.fit(X_train_synth, y_train_synth)\n",
    "print(\"R cuadrado para los datos sintéticos utilizando el modelo propio: %s\" % lr_synthetic.rsquare(X_test_synth, y_test_synth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R cuadrado para los datos sintéticos utilizando sklearn: 0.6397809665821652 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as sklr\n",
    "\n",
    "print(\"R cuadrado para los datos sintéticos utilizando sklearn: %s \" % sklr().fit(X_train_synth, y_train_synth).score(X_test_synth,y_test_synth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, al aplicar la regresión lineal desarrollada a un conjunto de datos sintético se obtiene un resultado con un R cuadrado alto y comparable con el obtenido si se utiliza la librería sklearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
